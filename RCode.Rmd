---
title: 'R code for the course materials'
author: "Dr Nemanja Vaci"
date: "March 14, 2023"
output:
   html_document:
    toc: true
    theme: united
---

```{r,echo=FALSE,message=FALSE,warning=FALSE}
# Set so that long lines in R will be wrapped:
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80), tidy=TRUE)
```

This document outlines the R code that was used across the lectures for Advanced Statistics course at MSc in Psychological Research Methods programme at the University of Sheffield, UK. The code follows the lectures, but also expands on the content covered by the lecture.

# Lecture 1: Linear regression

## Introduction

First, we used the dataset that are included in R packages. We can see what data do we have in standard R packages by calling: data() or we can see datasets specific for certain R packages by calling: data(package='lme4'). 

In this case, we can call pre-loaded dataset __cars__. More information on this data is available by calling ?cars or help(cars). 

```{r}
data("cars") #calls the dataset
head(cars) # prints first 6 observations in the dataset
```

We can use scatter plot to see the raw values.

```{r}
plot(cars$speed, cars$dist, xlab='Predictor', ylab='Outcome') #As this plot was only used to make an illustration of the linear regression, we changed the labels of x and y-axis. This was done using xlab and ylab parameters. You can change the name of the labels using the same code, eg. xlab='Speed (mph)', ylab='Stopping distance (ft)'
abline(lm(dist~speed, data=cars), lwd=2) #abline function adds one or more straight lines through the plot that you have active in your environment. lm function is used to fit linear models, where dist is modelled as a function of speed. We also indicate that values for distance and speed can be found in the cars dataset (data = cars). Finally, we specify the thickness of abline function with lwd=2 parameter. 
```

## Data simulation

We can also simulate some data: 

```{r}
set.seed(456) # we can set starting numbers that are used to generate our random values. Random numbers are rarely truly random: https://engineering.mit.edu/engage/ask-an-engineer/can-a-computer-generate-a-truly-random-number/
Babies=data.frame(Age=round(runif(100,1,30)),  Weight=rnorm(100,4000,500)) #We create a new data frame (Babies) where we have Age and Weight as variables. 100 Age values are sampled from random uniform distribution (runif) with lower bound of 1 (minimum) and upper bound of 30 (maximum). 100 Weight values are generated using random normal distribution (rnorm) with mean of 4000 and SD of 500 
Babies$Height=rnorm(100,40+0.2*Babies$Age+0.004*Babies$Weight, 5) # Height is generated using random normal distribution where mean is a function of Age and Weight, while SD is 5. 
Babies$Gender=factor(rbinom(100,1,0.5)) # 100 Gender values are generated using random binomial function with equal probability of being assigned one or the other sex category
levels(Babies$Gender)=c('Girls','Boys') #We levels function to assign Girls and Boys labels to 1 and 0 levels generated by the function
```

We can plot and inspect raw data:

```{r}
par(mfrow=c(1,3), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16) # par parameter sets global plotting settings. mfrow indicates number of panels for plots (1 row and 3 columns), bty sets type of box around the plot, mar defines margines around the plot, cex magnifies size of labels, while pch sets type of points used in the plot.
plot(Babies$Age, Babies$Height, xlab='Age (months)', ylab='Height (cm)')
plot(Babies$Weight, Babies$Height, xlab='Weight (grams)', ylab='Height (cm)')
boxplot(Babies$Height~Babies$Gender,xlab='Gender', ylab='Height (cm)')
```

We can also check the coding and formatting of the variables in our data frame. 

```{r}
str(Babies)
```

Finally, we can also load the dataset from our local disc drives. The datasets should be placed in your working environment. There are a number of tutorials that guide you how to optimise creation of the new projects, which results in all of your data, code and files being generated and saved at one place. https://r4ds.had.co.nz/workflow-projects.html 

```{r}
inequality<-read.table('inequality.txt', sep='\t', header=T) # read a file in table format and create a data frame from it. sep parameter defines separator in the data - tab delimited format in this case, while it could be also anything else, such as ',' - comma separated values, ' ' - space separated values etc. Header = T defines that the names of the variables are in the first row of the database.

#You can also numerous other extensions, suchs spss sav files, however you will often need additional packages for this. 
#Foreign package - library(foreign) has read.spss function that can be used to read in spss files dataExample<-read.spss('Example.sav', to.data.frame=T)
```

## Linear regression

### One predictor

```{r}
lm1<-lm(Height~Age, data=Babies) # linear model where Height is modelled as a function of Age. 
lm1$coefficients # We can print only the coefficients
```

```{r}
summary(lm1$coefficients) #We can also part of the information that is frequently used to judge significance and importance of predictors  
```

### Two predictors

```{r}
lm2<-lm(Height~Age+Gender, data=Babies) # linear model where Height is analysed as a function of Age and Gender
lm2$coefficients
```

### Main effects and interaction (numerical x categorical)

```{r}
lm3<-lm(Height~Age*Gender, data=Babies) # linear model where Height is modelled as a function of Age and Gender, as well as their interaction
lm3$coefficients
```

### Main effects and interaction (numerical x numerical)

```{r}
lm4<-lm(Height~Age*Weight, data=Babies)
lm4$coefficients
```

### Other information that we get from the linear model

```{r}
lm1<-lm(Height~Age, data=Babies)
summary(lm1)
```

We can calculate R2 step-by-step. First, we need predictions from the model that includes predictor, as this will give us residual sum of squares. 

```{r}
Babies$lm1=predict(lm1, newdata = Babies) # predict Height based on our lm1 model.
Babies$diff=Babies$lm1-Babies$Height #calculate differences between predicted (lm1) and observed values (Height) 
```

We can plot these differences using ggplot. 

```{r}
require(ggplot2)
ggplot()+geom_linerange(data=Babies,aes(x=Age, ymin=Height,ymax=lm1,colour=diff), size=1.2)+geom_line(data=Babies,aes(x=Age, y=lm1), size=1.2)+geom_point(data=Babies, aes(Age, y=Height), size=2)+ylab('Height')+xlab('Age')+ggtitle('SS_residual')
```

A second ingredient for our determination coefficient is sum of squares of total variation in the data. This we can get by building model with intercept only.

```{r}
lm0<-lm(Height~1, data=Babies)
summary(lm0)
Babies$lm0=predict(lm0, newdata = Babies) #predict Height based on average value only
Babies$diff2=Babies$lm0-Babies$Height #calculate difference between predicted (lm0) and observed values (Height)
```

We can plot these differences using ggplot.

```{r}
ggplot()+geom_linerange(data=Babies,aes(x=Age, ymin=Height,ymax=lm0,colour=diff2), size=1.2)+geom_line(data=Babies,aes(x=Age, y=lm0), size=1.2)+geom_point(data=Babies, aes(Age, y=Height), size=2)+ylab('Height')+xlab('Age')+ggtitle('SS_total')
```

The R2 coefficient is:

```{r}
1-(sum(Babies$diff^2)/(sum(Babies$diff2^2)))
```

Improvement in our prediction:

```{r}
Babies$diff3=Babies$lm1-Babies$lm0 #Improvement based on the inclusion of Age as a predictor - differences between the predicted values from (lm1) and intercept only model (lm0)
```

```{r}
ggplot()+geom_linerange(data=Babies,aes(x=Age, ymin=lm1,ymax=lm0,colour=diff3), size=1.2)+geom_line(data=Babies,aes(x=Age, y=lm0), size=1.2)+geom_line(data=Babies, aes(Age, y=lm1), size=1.3, linetype='dotdash')+geom_point(data=Babies, aes(x=Age, y=Height), size=0.9)+ylab('Height')+xlab('Age')+ggtitle('Improvement')+theme(axis.title=element_text(size=14), axis.text =element_text(size=12))
```

F-value:

```{r}
(sum(Babies$diff3^2)/1)/(sum(Babies$diff^2)/98)
```

## Practical aspect of the lecture

```{r}
inequality<-read.table('inequality.txt',sep=',', header=T)#Reading the data in R
head(inequality)
```

Probability density plots: outcomes

```{r}
par(mfrow=c(1,2))
plot(density(inequality$hate_crimes_per_100k_splc, na.rm = T), main='Crimes per 100k') #probability density for hate crimes outcomes. na.rm=T indicates that only cases that are not NAs should be returned
plot(density(inequality$avg_hatecrimes_per_100k_fbi, na.rm = T), main='Average Crimes')
```

Probability density plots: predictors

```{r}
par(mfrow=c(1,2))
plot(density(inequality$median_household_income, na.rm = T), main='Income')
plot(density(inequality$gini_index, na.rm = T), main='Gini')
```

Scatter plots:

```{r}
par(mfrow=c(1,2))
plot(inequality$median_household_income, inequality$avg_hatecrimes_per_100k_fbi, xlab='Median household income',ylab='Avg hatecrimes')
plot(inequality$gini_index, inequality$avg_hatecrimes_per_100k_fbi,xlab='Gini index',ylab='Avg hatecrimes')
```

```{r}
cor(inequality[,c(2,8,12)], use="complete.obs") #calculate correlations where we use only rows that have all values (no NAs). We are only focusing on columns: 2,8 and 12. inequality is a data frame with (n rows, m columns), so we can access only first row by calling inequality[1,], or just first column by inequality[,1], first row and first column would be inequality[1,1]. When using inequality[,c(2,8,12)] am asking for all rows but only second, eight and twelfth column.
```

Stepwise approach in building linear model

```{r}
mod1<-lm(avg_hatecrimes_per_100k_fbi~median_household_income, data=inequality) #modelling avg hatecrimes as a function of median_household_income
summary(mod1)
```

Adding a new predictor and comparing it with the previous model.

```{r}
mod2<-lm(avg_hatecrimes_per_100k_fbi~median_household_income+gini_index, data=inequality)
anova(mod2) #anova type comparison of the model that allows us to see whether newly added predictor explained additional variation in the outcome. We can see changes in the Sum Sq for residuals and for the main effects
```

We can also test whether there is need to adjust influence of median household income across the values of gini index - interaction between our predictors

```{r}
mod3<-lm(avg_hatecrimes_per_100k_fbi~median_household_income*gini_index, data=inequality)
anova(mod1,mod2, mod3) # comparison between three models
```

Summary of the model:

```{r}
summary(mod3)
```

We can visualise the interactions using __interactions__ package.

```{r}
require(interactions)
interact_plot(mod3, pred=median_household_income, modx=gini_index, plot.points = T)
```

Interactive visualisation:

```{r}
simulatedD<-data.frame(median_household_income=rep(seq(35500, 76165, by=100), 13), gini_index=rep(seq(0.41,0.53, by=.01), each=407))
simulatedD$Avg_hate_pred<-predict(mod3, newdata=simulatedD) #We need to simulate full matrix of observations - each combination of Gini index and Median Income (increments of 0.1 and 100, respectivelly). Then we predict observations based on our model and use the Simulated data as our predictors. 
```

```{r,fig.width=14, fig.height=5, fig.align='center'}
p<-ggplot(simulatedD, aes(median_household_income, Avg_hate_pred, color=gini_index,frame=gini_index))+geom_point() # Using ggplot to make the plot
plotly::ggplotly(p) #make it interactive using plotly
```

## Model diagnostics

Quantile-quantile plot: Normality

```{r,fig.width=10, fig.height=4,fig.align='center'}
car::qqPlot(mod3)
```

Homoscedasticity: Linearity

```{r,fig.width=10, fig.height=4,fig.align='center'}
car:: residualPlot(mod3, type='rstudent') # we can call car package without loading it into R environment by calling car::
```

Outliers:

```{r}
car:: influenceIndexPlot(mod3) #influence of individual observation on our model
```

Autocorrelation of residuals

```{r}
par(bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
stats::acf(resid(mod3))
```

Predicted versus observed data:

```{r}
par(bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(predict(mod3),mod3$model$avg_hatecrimes_per_100k_fbi, xlab='Predicted values (model 3)', ylab='Observed values (avg hatecrimes)') #The x-axis is predict(mod3) - predict values based on our model. The y-axis is the data that was used to build the model. I decided to take these values from our model frame (mod3), instead of original data frame (inequalities). 
```

Finally, we can subset our model and exclude data point that might skew our results

```{r}
mod3.cor<-lm(avg_hatecrimes_per_100k_fbi~median_household_income*gini_index, data=inequality, subset=-9) #We subset our data to exclude row 9
summary(mod3.cor)
```

# Lecture 2: Logistic regression

## Data simulation 

We can also simulate categorical outcomes.

```{r}
set.seed(456)
Babies=data.frame(Age=round(runif(100,1,30)), Weight=rnorm(100,4000,500))
Babies$Height=rnorm(100,40+0.2*Babies$Age+0.004*Babies$Weight, 5)
Babies$Gender=rbinom(100,1,0.5)
Babies$Crawl=rbinom(100,1,0.031*Babies$Age+0.00001*Babies$Weight-0.06*Babies$Gender) #I simulated Crawling data from random binomial distribution, where I took out 100 times 1 sample. Probability of success was defined in relation to Babies Age, Weigh and Gender. 
Babies$Gender=as.factor(Babies$Gender) # I recode these numbers to factor
levels(Babies$Gender)=c('Girls','Boys') # Assigning labels to Gender factor
table(Babies$Crawl)
```

Plotting probability density function for Number of babies crawling in our data 

```{r,fig.width=14, fig.height=5, fig.align='right'}
par(mfrow=c(1,1), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(1:100,dbinom(1:100,0.63, size=100), xlab='N of babies crawling', ylab='Probability', type='l')
```

## Relation between log odds, odds, and probabilities

```{r, message=FALSE, fig.width=12, fig.height=5, fig.align='center'}
require(ggplot2) #load in ggplot2
logit<-data.frame(LogOdds=seq(-2.5,2.5, by=.1), Pred=seq(-2.5,2.5, by=.1)) #create data frame where variable LogOdds containts numbers from -2.5 to 2.5 changing by 0.1 
logit$Odds=exp(logit$LogOdds) #exponentiate logits that results in odds
logit$Probabilities=logit$Odds/(1+logit$Odds) #transform odds ratios to probabilities 

ggplot(data = logit, aes(x=Pred, y=Odds))+geom_point(size=2)+theme_bw()+ylim(0,13)+theme(axis.title=element_text(size=14), axis.text =element_text(size=12)) #plotting odds
```

Plotting Log-Odds: 

```{r}
ggplot(data = logit, aes(x=Pred, y=LogOdds))+geom_point(size=2)+theme_bw()+ylim(-4,4)+theme(axis.title=element_text(size=14), axis.text =element_text(size=12))
```

Plotting probabilities:

```{r}
ggplot(data = logit, aes(x=Pred, y=Probabilities))+geom_point(size=2)+theme_bw()+ylim(0,1)+theme(axis.title=element_text(size=14), axis.text =element_text(size=12))
```

We can again check what is in our simulated data:

```{r}
par(mfrow=c(1,3), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(Babies$Age, Babies$Height, xlab='Age (months)', ylab='Height (cm)')
boxplot(Babies$Height~Babies$Gender,xlab='Gender', ylab='Height (cm)')
boxplot(Babies$Age~Babies$Crawl,xlab='Crawl', ylab='Age (months)') #Boxplot of Babies Age across our Crawling outcome, xlab - label of x-axis, ylab - label of y-axis
```

## Logistic regression model

Let's build first logistic regression model:

```{r}
glm1<-glm(Crawl~Age, data=Babies, family=binomial(link='logit')) #glm function is used to fit generalized linear models (try typing in your console: ?glm). Crawl is modelled as a function of Age and we are using Babies data. Family specified type of the outcome distribution. We are saying that this our oucome follows Binomial distribution, while we want to use logit link - logOdds transformation. 
glm1$coefficients #we are printing only coefficients
```

Let's get Odds:

```{r}
glm1$coefficients
exp(glm1$coefficients) #we can use exponential function to transform our coefficients to Odds ratios - how more likely it is that babies are going to start crawling if they are older by 1 month (beta coefficient - slope)
```

Let's get probabilities:

```{r}
1/(1+exp(1.33078)) # only intercept
1/(1+exp(1.33078-0.11948*10)) #What is the probability of babies starting to crawl when they are 10 months?
arm::invlogit(coef(glm1)[[1]]+coef(glm1)[[2]]*mean(Babies$Age)) # what is the probability of babies starting to crawl when they are mean of their age (around 16 months). I used invlogit function to automatically calculate probabilities. coef(glm1)[[1]] - gives me intercept value, while coef(glm1)[[2]] - gives me slope value for age.
```

We can plot inner workings of our model: Logit, odds and probabilities 

```{r}
Babies$LogOdds=-1.33078+0.11948*Babies$Age #Outputing logit values based on our model
Babies$Odds=exp(Babies$LogOdds) #Transforming them to odds 
Babies$Probs=Babies$Odds/(1+Babies$Odds) # Transforming odds to probabilities
par(mfrow=c(1,3), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(Babies$Age,Babies$LogOdds)
plot(Babies$Age, Babies$Odds)
plot(Babies$Age,Babies$Probs)
```

Lets see what goes into the model and how our model sees the data:

```{r}
ggplot(data=Babies, aes(x=Age, y=Probs))+geom_point(size=2, col='blue')+geom_point(data=Babies, aes(x=Age, y=Crawl), size=2, col='red') #Red points show our dependent outcome - 0,1; blue points show estimated probabilities across the values of Age. 
```

### Summary of the results

```{r}
summary(glm1) #Summary of the complete model
```

We can calculate whether our proposed model is improvement in comparison to the null (only intercept model) - statistically significant:

```{r}
with(glm1, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)) #I am asking R to take values from my glm1 object (our model), where I am asking him to take p-values from chi-square distribution where my values are difference between null deviance model and our my fitted model, differences in the degrees of freedom, and we are looking at the right side of the probability distribution with lower.tail=FALSE
```

## Practical aspect:

```{r}
basketball<-read.table('Basketball.txt',sep='\t', header=T) #Loading the data in R. Data file is .txt file, where separator is tab delimited (tab delimited values) and the names of my variables are in the first row (header=T)
knitr::kable(head(basketball[,c(5,13,18,31,34,43)]), format = 'html') #Printing only certain columns (numbers in c())
```

Let's plot the data to see how it looks like:

```{r, fig.width=12, fig.height=5, fig.align='center'}
table(basketball$Win) #Tabulate outcome
par(mfrow=c(1,2), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(density(basketball$X3PointShots.), main='', xlab='3POintsShots')
plot(density(basketball$Opp.3PointShots.), main='', xlab='Opp3PointsShots')
```

We can also cross-tabulate the data. Focus on combinations of categories:

```{r}
knitr::kable(table(basketball$Win, basketball$Home), format = 'html')
datA=aggregate(cbind(basketball$X3PointShots., basketball$Opp.3PointShots., basketball$FreeThrows., basketball$Opp.FreeThrows.), list(basketball$Win), mean) #aggregate function aggregates our data. I used this function to calculate arithmetic mean for X3POintsShots, Opp3Points shots, FreeThrows, OppFreeThrows for each outcome value (0,1). cbind is used to join all numerical values together in one dataframe. In other words, we are not aggregating one by one numerical variable, as cbind allows us to do that jointly. Instead of mean, you can use sd or min or max or whatever you want.  
names(datA)=c('Win','X3POints_mean','Opp3POints_mean','FreeThrows_mean','OppFreeThrows_mean') #as my aggregate returns new data frame without the names of the variables I just quickly attach the names to them.
knitr::kable(datA, format = 'html') #Writting it out
```

Plotting predictors and categorical outcome

```{r, fig.width=12, fig.height=5, fig.align='center'}
par(mfrow=c(1,2), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(basketball$X3PointShots.,basketball$Win)
plot(basketball$X3PointShots.,jitter(basketball$Win, 0.5))
```

Let's make first model (one predictor):

```{r}
baskWL1<-glm(Win~Home, data=basketball, family=binomial('logit')) #Main effect of Home
summary(baskWL1)
```

Model with two predictors: 

```{r, size="tiny"}
baskWL2<-glm(Win~Home+X3PointShots., data=basketball, family=binomial('logit')) #Main effect of home and X3PointsShots.
summary(baskWL2)
```

Model comparison (model 2 versus model 1)

```{r}
anova(baskWL1, baskWL2, test = "LR") #compare two models where we use likelihood ratio test - for generalized linear models  
```

Three predictors:

```{r, size="tiny"}
baskWL3<-glm(Win~Home+X3PointShots.+Opp.3PointShots., data=basketball, family=binomial('logit')) #Main effect of Home, X3PointsShots. and Opp.3PointsShots.
anova(baskWL1,baskWL2, baskWL3, test = "LR") #comparing three models
```

Interactions:

```{r, size="tiny"}
baskWL4<-glm(Win~Home*X3PointShots.+Opp.3PointShots., data=basketball, family=binomial('logit')) #Three main effects and interaction between Home and X3PointsShots
anova(baskWL3, baskWL4, test = "LR") #comparing third and fourth model
```

Visualising our model with two predictors:

```{r,fig.width=12, fig.height=5, fig.align='center'}
basketball$Prob_mod2=predict(baskWL2, type='response')
ggplot(data=basketball, aes(x=X3PointShots., y=Prob_mod2, colour=Home))+geom_point(size=2)+geom_point(data=basketball, aes(x=X3PointShots., y=Win), size=2, col='blue')
```

Visualising our model with three predictors

```{r,fig.width=12, fig.height=5, fig.align='center'}
basketball$Prob_mod3=predict(baskWL3, type='response')
ggplot(data=basketball, aes(x=X3PointShots., y=Prob_mod3, colour=Home))+geom_point(size=2)+geom_point(data=basketball, aes(x=X3PointShots., y=Win), size=2, col='blue')
```

It is quite nice to report confidence intervals in your work:

```{r}
confint(baskWL3)#confidence intervals for logit estimates in our third model
exp(confint(baskWL3))#confidence intervals for odds ratios in our third model
```

Let's see how accurate is our model:

```{r}
Ctabs<-table(basketball$Win,basketball$Prob_mod3>0.5)
Ctabs
```

# Lecture 3: Mixed-effect models

## Theoretical part

### Simulation of the data with hierarchical categories

```{r, warning=FALSE, message=FALSE}
set.seed(456)
#Fixed effects
alpha_0 <-500 #intercept
beta_1 <-50 #slope 
sigma <- 100 #sd

# by-intercept sd, by_slope sd and correlation between intercept and slope sd
tau_0 <- 30 # by-group random intercet (countries)

tau_1 <- 30 # by-group random slope (countries)
rho <- 0

n_babies<-10

n_rfx <- faux::rnorm_multi(
    n=n_babies,
    mu = 0,
    sd = c(tau_0, tau_1),
    r = rho,
    varnames = c('T_0s','T_1s')
)

babies_rfx=data.frame(T_0s=rep(n_rfx$T_0s, each=200), T_1s=rep(n_rfx$T_1s, each=200))

Babies <- data.frame(Babies_id = rep(1:10, each=200),
                     babies_rfx)

Babies$Age=round(runif(2000,1,30))
Babies$Surounding=rnorm(2000,Babies$T_0s,20)
Babies$Weight=rnorm(2000,20,10)
Babies$CalorieIntake=alpha_0 + Babies$T_0s+(beta_1+Babies$T_1s)*Babies$Age+4*Babies$Surounding+5*Babies$Weight+rnorm(2000,0,sigma)
```

```{r}
table(Babies$Babies_id) #How many observations we have for each group
```

### Complete pooling model

Linear model where we ignore information about the countries: 

```{r}
mod1CP<-lm(CalorieIntake~Age, data=Babies)
summary(mod1CP)
```

Looking at residuals:

```{r, fig.width=12, fig.height=5, fig.align='center'}
par(mfrow=c(1,1), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(resid(mod1CP)[1:200], ylab='Residuals', xlab='Index')
```

### No pooling model

Linear model where we estimates parameters for each country separately:  

```{r}
mod1NP<-lm(CalorieIntake~Age+factor(Babies_id)-1, data=Babies)
summary(mod1NP)
```

Looking at residuals:

```{r, fig.width=12, fig.height=5, fig.align='center'}
par(mfrow=c(1,1), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(resid(mod1CP)[1:200], ylab='Residuals', xlab='Index')
```

### Multilevel model: intercept

```{r, warning=FALSE, message=FALSE}
#install.packages('lme4')
require(lme4)

mult1<-lmer(CalorieIntake~Age+(1|Babies_id), data=Babies)
summary(mult1)
```

### Multilevel model: intercept and slope adjustments 

```{r}
mult2<-lmer(CalorieIntake~Age+(1+Age|Babies_id), data=Babies)
summary(mult2)
```

### Comparison of residuals

```{r, fig.width=12, fig.height=5, fig.align='center'}
par(mfrow=c(1,3), bty='n',mar = c(5, 4,1, .1), cex=1.1, pch=16)
plot(resid(mod1CP)[1:200], ylab='Residuals',xlab='Index', main='Complete pooling')
plot(resid(mod1NP)[1:200], ylab='Residuals',xlab='Index', main='No pooling')
plot(resid(mult2)[1:200], ylab='Residuals',xlab='Index', main='Partial pooling')
```

### Fixed and random effects

```{r}
fixef(mult2)
```

```{r}
ranef(mult2)
```

### Intra-class correlation (ICC)

```{r}
mod1<-lmer(CalorieIntake~Age+(1|Babies_id), data=Babies)
performance::icc(mod1)
```

### Significance testing: fixed effects

```{r, warning=FALSE, message=FALSE}
#install.packages('lmerTest')
require(lmerTest)
mult2<-lmer(CalorieIntake~Age+(1+Age|Babies_id), data=Babies)
print(summary(mult2), cor=F)
```

## Practical aspect

```{r, warning=FALSE, message=FALSE}
#install.packages('foreign')
require(foreign) #to read-in the data that are SPSS format (.sav) we need foreign package
mwell<-read.spss('data.sav', to.data.frame = T) #read.spss function and we specify that we should read it as a data frame
dim(mwell) #dimensions of our data (number of rows and columns)
mwell$Total=mwell$Watchwe_adj+mwell$Watchwk_adj+mwell$Comphwe_adj+mwell$Comphwk_adj+mwell$Smartwe_adj+mwell$Smartwk_adj #total amount of time spent watching screen in a week
```

### Number of missing values in our outcome:

```{r}
table(is.na(mwell$mwb))
```

### Numbe of missing values in our predictor:

```{r}
table(is.na(mwell$Watchwk))
```

### Density plots for our variables

```{r, fig.width=12, fig.height=5, fig.align='center'}
par(mfrow=c(1,2), bty='n',mar = c(5, 4, .1, .1), cex=1.1,pch=16)
plot(density(mwell$mwb, na.rm=TRUE), main='')
plot(density(mwell$Total, na.rm = T), main='')
```

### Subsetting the data - excluding NAs:

```{r}
mwell2=mwell[!is.na(mwell$mwb) & !is.na(mwell$Total),] # we are trying to subset our data frame and take only values that are not NAs. is.na is a boolean function that tells us whether one row is NA or not (TRUE or FALSE). !is.na indicates that we do not want TRUE na.values. We also have a logical parameter & that combines two conditions !is.na(outcome) & !is.na(predictor). Finally, we would like to filter our dataset by row and exclude all the rows that have either TRUE value in our predictor or our outcome. Therefore, we are looking at rows mwell[function goes here,] instead of mwell[,function goes here ] which would look at columns 
dim(mwell2) #dimensions of the smaller data
```

### Scatter plot:

```{r, fig.width=12, fig.height=5, fig.align='center'}
cor(mwell2$mwb, mwell2$Total)
par(mfrow=c(1,1), bty='n',mar = c(5, 4, .1, .1), cex=1.1,pch=16)
plot(mwell2$Total[1:500], mwell2$mwb[1:500])
```

### Number of observations for each of our potential random structures:

```{r}
table(mwell2$Ethnicg)
table(mwell2$REGION)
```

### Building the model: 

```{r}
MWmod1<-lmer(mwb~(1|LANAME), data=mwell2) #random effect of Local area
MWmod2<-lmer(mwb~(1|LANAME)+(1|Ethnicg), data=mwell2) #crossed random effects of local area and ethnicity
MWmod3<-lmer(mwb~(1|REGION/LANAME)+(1|Ethnicg), data=mwell2) #nested random effect of local area that is nested in region and crossed with ethnicity
anova(MWmod1, MWmod2, MWmod3) #comparison of the models
```

### Building the model: Fixed structure 1

```{r}
MWmod2a<-lmer(mwb~Total+(1|LANAME)+(1|Ethnicg), data=mwell2) #main effect of total
print(summary(MWmod2a), cor=F)
```

### Building the model: Fixed structure 2

```{r}
MWmod2b<-lmer(mwb~Total+male+(1|LANAME)+(1|Ethnicg), data=mwell2) #main effect of total and main effect of sex
MWmod2c<-lmer(mwb~Total*male+(1|LANAME)+(1|Ethnicg), data=mwell2) #interaction between total and sex
anova(MWmod2a, MWmod2b, MWmod2c)#comparison of the models 
```

```{r}
print(summary(MWmod2c), cor=F)
```

### Random structure: random slopes

```{r}
MWmod3c<-lmer(mwb~Total*male+(1+Total|LANAME)+(1|Ethnicg), data=mwell2) #random slopes for total predictor for Local area and intercept for local area 
```

```{r}
MWmod3c<-lmer(mwb~Total*male+(1|LANAME:male)+(1|Ethnicg), data=mwell2) #random intercept for unique combination between local area and sex 
anova(MWmod2c, MWmod3c) #comparison of the models
```

```{r}
MWmod3c<-lmer(mwb~Total*male+(1|LANAME)+(1|Ethnicg:male), data=mwell2) #random intercepts for unique combination between Ethnicity and sex
anova(MWmod2c, MWmod3c)
```

```{r}
summary(MWmod3)
```

### Visualisation of the random structure:

```{r, warning=FALSE, message=FALSE, fig.width=12, fig.height=5, fig.align='center'}
require(sjPlot)
plot_model(MWmod3c, type='re', sort.est='sort.all', grid=FALSE)[1] #type='re' gives us random adjustments, while [1] indicates that we want only first plot
```

```{r , fig.width=12, fig.height=5, fig.align='center'}
plot_model(MWmod3c, type='re', sort.est='sort.all', grid=FALSE)[2]
```

### Visualisation of the fixed effects (interaction): 

```{r, warning=FALSE, message=FALSE, fig.width=12, fig.height=5, fig.align='center'}
plot_model(MWmod3c, type='int')
```

### Significance of the random effects

```{r}
ranova(MWmod3c)
```

### Explained variance - R2

```{r, warning=FALSE, message=FALSE}
#install.packages('MuMIn')
require(MuMIn)
r.squaredGLMM(MWmod3c) # m stands for marginal, while c stands for conditional. Marginal is approximation of the explained variance by fixed-effect structure, while conditional is with both fixed and random-effect structure
```

### Predictions of the model

```{r, fig.width=12, fig.height=5, fig.align='center'}
mwell2$predicted=predict(MWmod3c) #prediction values from model to our train dataset
par(mfrow=c(1,1), bty='n',mar = c(5, 4, .1, .1), cex=1.1,pch=16)
plot(mwell2$predicted, mwell2$mwb) #plot predicted versus observed data points
```

# Week 4: Structural Equation Modelling
## Confirmatory factor analysis

## Theoretical part

### Data simulation

```{r}
set.seed(456)
Babies=data.frame(Age=round(runif(100,1,30)), Weight=rnorm(100,4000,500))
Babies$Height=rnorm(100,40+0.2*Babies$Age+0.004*Babies$Weight, 5)
Babies$Gender=rbinom(100,1,0.5)
Babies$Crawl=rbinom(100,1,0.031*Babies$Age+0.00001*Babies$Weight-0.06*Babies$Gender)
Babies$TummySleep=rbinom(100,1,0.5)
Babies$PhysicalSt=rnorm(100,10+0.3*Babies$Height+0.1*Babies$Age-0.06*Babies$Gender+0.15*Babies$TummySleep,5)
Babies$Gender=as.factor(Babies$Gender)
levels(Babies$Gender)=c('Girls','Boys')
```

```{r}
#install.packages('faux')
require(faux)
set.seed(456) #seed specification for the data simulation

#Here I am specifying a correlation matrix for 6 variables. The correlation matrix has 6*6 = 36 values and codes all correlations for variable-by-variable relations. The first value in the first row is correlation of var1 with itself, then we go to var1-var2, var1-var3,... Second row starts with the var2-var1, then var2-var2... 

cmat <- c(1, .4,.4, .1, .1, .1,
          .4, 1,.3, .1, .1, .1,
          .4,.2, 1, .1, .1, .1,
          .1,.1,.1,  1, .4, .4,
          .1,.1,.1, .4,  1, .2,
          .1,.1,.1, .4, .2,  1)

vars<-rnorm_multi(n=100, 6,30,5,cmat) # now we take that correlation matrix and simulate 6 variables with 100 values with mean of 30 and sd of 5. 

names(vars)=c('TimeOnTummy','PreciseLegMoves','PreciseHandMoves','Babbling','Screeching','VocalImitation') #Naming of the columns in the vars dataset. 

Babies=cbind(Babies,vars) #combination of Babies data set with new variables. Cbind (Column bind) function adds new columns to Babies dataset. 
```

### Covariance matrix

```{r}
Matrix<-cov(vars)
Matrix[upper.tri(Matrix)]<-NA
knitr::kable(Matrix, format = 'html')
```

### Model building

```{r, message=FALSE, warning=FALSE}
#install.packages('lavaan')
require(lavaan) #package for our cfa function
model1<-'
motor =~ TimeOnTummy + PreciseLegMoves + PreciseHandMoves
verbal =~ Babbling + Screeching + VocalImitation
' # our motor LV is regressed onto TimeOnTummy, PreciseLegMoves and PreciseHandMoves, while our verbal LV is regressed onto Babbling, Screeching and VocalImitation. We used reflective coding =~ for LVs indicating that we assume that our LV is causing/influencing behaviour measured in our dataset. 

fit1<-cfa(model1, data=Babies) #fitting the model
summary(fit1) #summary of the results
```

### Summary with standardised values

```{r}
summary(fit1, standardized=TRUE) #with standardised values 
```

### Model 2: scaling the factors by seting variance to 1: 

```{r}
model2<-'
motor =~ NA*TimeOnTummy + PreciseLegMoves + PreciseHandMoves
verbal =~ NA*Babbling + Screeching + VocalImitation
motor ~~ 1*motor
verbal ~~ 1*verbal
'
# In this situation we used same specification of the latent factors, but we change the way how the scale of latent variables is defined. We are defining the scale by seting variance of LVs to 1, this is done with motor ~~ 1*motor and verbal ~~ 1*verbal. We also include NA* to two first variables (that are always used to scale LVs) that we would like to estimate.  

fit2<-cfa(model2, data=Babies)
summary(fit2, standardized=TRUE)
```

### Model 3: Scaling LVs by effect coding

```{r}
model3<-'
motor =~ NA*TimeOnTummy+a*TimeOnTummy + b*PreciseLegMoves + c*PreciseHandMoves
verbal =~ NA*Babbling+a1*Babbling + b1*Screeching + c1*VocalImitation
a+b+c==3
a1+b1+c1==3
'

# In this situation we used same specification of the latent factors, but we change the way how the scale of latent variables is defined. We are defining the scale by constraining the loadings of manifest variables to latent variable to be the exactly as number of manifest variables loaded onto factor (3 manifest variable == 3). We need to specify that we would like for model to estimate the loading of the first manifest variable:  NA*TimeOnTummy, but also label coefficients with a, b, c, and finally make a constraint that a+b+c == 3 

fit3<-cfa(model3, data=Babies)
summary(fit3, standardized=TRUE)
```

### Adding intercepts to our model:

```{r}
model3<-'
motor =~ TimeOnTummy + PreciseLegMoves + PreciseHandMoves
verbal =~ Babbling + Screeching + VocalImitation
TimeOnTummy ~ 1
PreciseLegMoves ~ 1
PreciseHandMoves ~ 1
Babbling ~ 1
Screeching ~ 1 
VocalImitation ~ 1'
# Model stays again identical to the first one (scaled by the measure of first variables), however we add TimeOnTummy ~ 1 and this is identical for all measured variables.
fit3<-cfa(model3, data=Babies)
summary(fit3, standardized=TRUE, fit.measures=T)
```

### Indices of global model fit

```{r}
summary(fit1, fit.measures=TRUE)
```

### Structural equation model: CFA + Path

```{r}
model4<-'
#CFA model
motor =~ TimeOnTummy + PreciseLegMoves + PreciseHandMoves
verbal =~ Babbling + Screeching + VocalImitation

#Path model
motor ~ Age + Weight
verbal ~ Age + Weight
'

fit4<-sem(model4, data=Babies)
summary(fit4, standardized=TRUE)
```

### Measurement invariance
#### Configural invariance

```{r, warning=FALSE, message=FALSE}
modelMI<-'
motor =~ TimeOnTummy + PreciseLegMoves + PreciseHandMoves
verbal =~ Babbling + Screeching + VocalImitation
'

fitMIC<-cfa(modelMI, data=Babies, group='Gender') # for configural invariance we can specify group gender and leave all other parameters to be unrestricted
summary(fitMIC)
```

#### Metric invariance

In the case of metric invariance we would like to compare loadings on the factor structures between the two groups. If there are no differences between the models (model without restricted loadings fitting worse), then we have same factor loadings between the groups. 

```{r, warning=FALSE, message=FALSE}
modelMI<-'
motor =~ TimeOnTummy + PreciseLegMoves + PreciseHandMoves
verbal =~ Babbling + Screeching + VocalImitation
'

fitMIM<-cfa(modelMI, data=Babies, group='Gender',group.equal='loadings') #we restrict the loadings on factors between two groups. 
summary(fitMIM)
```

```{r}
#install.packages('semTools')
require(semTools)
summary(compareFit(fitMIC, fitMIM)) # compareFit compares our two models and gives as an information of whether one is worse than the other. If model with restricted loadings is worse that is an indication that loadings are different. 
```

#### Scalar invariance

In the case of scalar invariance we would like to restrict both loadings and intercepts between two groups. Similar to the previous two invariances, when we compare the models if the scalar invariance model fits worse than metric invariance or configural invariance, then we can assume that intercepts or means are not identical between the groups. 

```{r}
modelMI<-'
motor =~ TimeOnTummy + PreciseLegMoves + PreciseHandMoves
verbal =~ Babbling + Screeching + VocalImitation
'

fitMISc<-cfa(modelMI, data=Babies, group='Gender',group.equal=c('loadings','intercepts')) #Restriction of the loadings and intercepts 
summary(fitMISc)
```

```{r}
summary(compareFit(fitMIM,fitMISc)) # comparison between measurement invariance and scalar invariance model
```

#### Strict invariance 

Strict invariance restricts loadings, intercepts and error variances. In this case, not only that we are assuming that all direct effects are identical (loadings and intercepts), but we also test whether unexplained variance is identical. This is akin to saying that the same data generating proces and structural effects can be assumed between the two groups. 

```{r}
modelMI<-'
motor =~ TimeOnTummy + PreciseLegMoves + PreciseHandMoves
verbal =~ Babbling + Screeching + VocalImitation
'

fitMISt<-cfa(modelMI, data=Babies, group='Gender',group.equal=c('loadings','intercepts','residuals')) #restricting loadings, intercepts and residuals
summary(fitMISt)
```

```{r}
summary(compareFit(fitMISc,fitMISt)) # model comparison
```

#### Finding differences between the models
If you have differences in the fit of the model, for example, between Measurement invariance and configural invariance model, you would like to see which parameters are different between the groups. You can do that using this function:

```{r}
lavTestScore(fitMISc)
```

## Practical part:

```{r, message=FALSE, warning=FALSE}
#install.packages('sem')
require(sem)
data('HS.data') # reading the HS data
```

### Descriptives: 

```{r}
dim(HS.data) #dimensions of the dataset
summary(HS.data[,c('visual','cubes','flags','paragrap','sentence','wordm','addition','counting','straight')]) # descriptive statistics for specific variables in our dataset
```

### Plots: 

```{r, warning=FALSE, message=FALSE,out.width = '40%',fig.align='center'}
#install.packages('psych')
require(psych)
scatter.hist(x=HS.data$visual,y=HS.data$cubes, density = T, ellipse = T) # bi-variate scatterplot for our data
```

### Specification of the model: 

```{r}
detach('package:sem')
fact3<-'
spatial =~ visual + cubes + flags
verbal =~ paragrap + sentence + wordm
speed =~ addition + counting + straight
'

fact3fit<-cfa(fact3, data=HS.data)
summary(fact3fit, fit.measures=TRUE ,standardized=TRUE)
```

### Explained variance - R2

```{r}
inspect(fact3fit,'r2') #get r2 for our measured variables
```

### Multivariate normality

```{r, warning=FALSE, message=FALSE}
#install.packages('MVN')
require(MVN)
test<-mvn(HS.data[,c('visual','cubes','flags','paragrap','sentence','wordm','addition','counting','straight')], mvnTest = 'royston') # multivariate normality for the variables used in our model
test$multivariateNormality
```

If we do not have multivariate normality, we can calculate robust errors and different test statistic

```{r}
fact3fitRob<-cfa(fact3, data=HS.data, se='robust.sem',test='satorra.bentler')
summary(fact3fitRob,standardized=TRUE)
```

### Modification indices

Finally, we can check modification indices and include some of them into our model. 

```{r}
mi <- modindices(fact3fitRob)
mi
```

### Change the model

```{r}
fact3A<-'
spatial =~ visual + cubes + flags + straight + addition
verbal =~ paragrap + sentence + wordm
speed =~ addition + counting + straight
'

fact3AfitRob<-cfa(fact3A, data=HS.data,se='robust.sem',test='satorra.bentler')
summary(fact3AfitRob, fit.measures=TRUE ,standardized=TRUE)
```

### Comparison of the new and original model

```{r}
diff<-compareFit(fact3fitRob, fact3AfitRob)
summary(diff)
```

## Path model

Adding more variables to our data. It just keeps growing: 

```{r, warning=FALSE, message=FALSE}
library(truncnorm)
require(lavaan)
set.seed(456)
Babies=data.frame(Age=round(runif(100,1,30)), Weight=rnorm(100,4000,500))
Babies$Height=rnorm(100,40+0.2*Babies$Age+0.004*Babies$Weight, 5)
Babies$Sex=rbinom(100,1,0.5)
Babies$Nutrition=rtruncnorm(n=100, a=0, b=30, mean=5, sd=10)
Babies$PhyExer=rnorm(100, 180,50)
Babies$GMA=rnorm(100, 180,50)
Babies$SocialBeh=rnorm(100, 180+Babies$PhyExer,80)
Babies$TummySleep=rbinom(100,1,0.5)
Babies$CognitiveAb=rnorm(100,10+7*Babies$Nutrition+0.1*Babies$PhyExer+3*Babies$GMA+0.03*Babies$PhyExer*Babies$SocialBeh,5)
Babies$Sex=as.factor(Babies$Sex)
levels(Babies$Sex)=c('Girls','Boys')
```

### Fitting the model:

```{r}
#install.packages('lavaan') - we need lavaan package to fit structural equation models, both path models and confirmatory factor analysis
require(lavaan)
#model has to be written in a separate object. We have quotation marks ('') to indicate that this is a textual input.
modelAbility<-'
SocialBeh~Nutrition+PhyExer+GMA
CognitiveAb~SocialBeh+Nutrition+GMA
'
#we use sem function to fit the model, while we specify that data is in the dataset Babies 
fit1<-sem(modelAbility, data=Babies)
summary(fit1)
```

We can also plot the estimates of our model: 

```{r, warning=FALSE, message=FALSE, fig.width=12, fig.height=5, fig.align='center'}
#install.packages('tidySEM')
require('tidySEM')
graph_sem(fit1, variance_diameter=.2)
```

### Indices of the model fit:

```{r}
summary(fit1, fit.measures=TRUE) # we need to include fit.measures=TRUE for lavaan to print them out
```

### Model modifications:

```{r , warning=FALSE, message=FALSE}
modelAbility2<-'
SocialBeh~Nutrition+PhyExer+GMA
CognitiveAb~SocialBeh+Nutrition+GMA+PhyExer
'
fit2<-sem(modelAbility2, data=Babies)
summary(fit2, fit.measures=TRUE)
```

### Model comparison:

```{r}
lavTestLRT(fit1,fit2) # we are comparing fit of the first and the second model
```

Check the modification indices:

```{r}
modindices(fit1, sort=TRUE) #we are checking them for the first model, high values indicate potential pathways that we could include and improve the model fit
```

### Calculation of the indirect pathways:

```{r, warning=FALSE, message=FALSE}
modelAbilityPath<-'
SocialBeh~Nutrition+a*PhyExer+GMA
CognitiveAb~b*SocialBeh+c*Nutrition+GMA

indirect := a*b
direct := c
total := indirect + direct
'
# multiplication sign (*) labels the parameter - assigns regression coefficient (PhyExer) to value a. 
 #using := we can specify calculations in the sem. You can do any other type of calculaton also, eg. a^2

fitPath<-sem(modelAbilityPath, data=Babies)
summary(fitPath)
```

### PiecewiseSEM package

```{r, warning=FALSE, message=FALSE}
#install.packages('piecewiseSEM)
require(piecewiseSEM)
model1<-psem(lm(SocialBeh~Nutrition+PhyExer+GMA, data=Babies),
             lm(CognitiveAb~SocialBeh+Nutrition+GMA, data=Babies)) # combined linear regression functions
summary(model1, .progressBar=FALSE)
```

## Practical aspect of the lecture

Getting the data

```{r}
NBAPath<-read.table('NBApath.txt', sep='\t', header=T)
```

### Summary of the NBA data

```{r}
summary(NBAPath)
```

### Correlation matrix

```{r}
cor(NBAPath[,c(2,5:7)]) #correlation between second, fifth, and seventh variable in the NBAPath dataframe
```

### Univariate plots

```{r, fig.width=12, fig.height=5, fig.align='center'}
par(mfrow=c(1,2), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(density(NBAPath$PER), main='')
plot(density(NBAPath$PCT), main='')
```

### Bivariate plots

```{r,fig.width=12, fig.height=5, fig.align='center'}
par(mfrow=c(1,2), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(NBAPath$Age, NBAPath$PER)
plot(NBAPath$GP, NBAPath$PER)
```

### Estimating the model

```{r}
NBAmod1<-'
GP~b*Age
PER~a*Age+c*GP

dir := a
ind := b*c
tot := dir + ind
'
NBAfit1<-sem(NBAmod1, data=NBAPath)
summary(NBAfit1)
```

### R2 and other measures of fit

```{r}
inspect(NBAfit1, 'r2')
-2*logLik(NBAfit1) # deviance 
AIC(NBAfit1) # Akaike information criterion
```

### Respecification of the model

```{r}
NBAmod2<-'
GP~b*Age
PER~c*GP

ind := b*c
'
NBAfit2<-sem(NBAmod2, data=NBAPath)
summary(NBAfit2, fit.measures=T)
```

### Model comparison

```{r, warning=FALSE, message=FALSE}
#install.packages('semTools')
require(semTools)
diff<-compareFit(NBAfit1, NBAfit2)
summary(diff)
```

### Respecification of the model 2

```{r, warning=FALSE, message=FALSE}
NBAmod3<-'
GP~b*Age
PER~a*Age+c*GP
PCT~d*PER
ind1 := b*c*d
ind2 := a*d
tot := ind1 + ind2
'
NBAfit3<-sem(NBAmod3, data=NBAPath)
summary(NBAfit3, fit.measures=T)
```

### Parameter estimates 

```{r}
parameterestimates(NBAfit3, boot.ci.type ='bca.simple', standardized = T)
#adding bca.simple we are getting bootstrapped intervals using adjusted bootstrap percentile method
```

### Bootstrapping our model

```{r, message=FALSE, warning=FALSE}
#install.packages('bootstrap')
require(bootstrap)
boot<-bootstrapLavaan(NBAfit3, R=1000)
summary(boot)
```

```{r}
sessionInfo()
```

