---
title: 'R code for the course materials'
author: "Dr Nemanja Vaci"
date: "February 08, 2022"
output:
   html_document:
    toc: true
    theme: united
---

```{r,echo=FALSE,message=FALSE,warning=FALSE}
# Set so that long lines in R will be wrapped:
knitr::opts_chunk$set(tidy.opts=list(width.cutoff=80), tidy=TRUE)
```

This document outlines the R code that was used across the lectures for Advanced Statistics course at MSc in Psychological Research Methods programme at the University of Sheffield, UK. The code follows the lectures, but also expands on the content covered by the lecture.

# Lecture 1: Linear regression

## Introduction

First, we used the dataset that are included in R packages. We can see what data do we have in standard R packages by calling: data() or we can see datasets specific for certain R packages by calling: data(package='lme4'). 

In this case, we can call pre-loaded dataset __cars__. More information on this data is available by calling ?cars or help(cars). 

```{r}
data("cars") #calls the dataset
head(cars) # prints first 6 observations in the dataset
```

We can use scatter plot to see the raw values.

```{r}
plot(cars$speed, cars$dist, xlab='Predictor', ylab='Outcome') #As this plot was only used to make an illustration of the linear regression, we changed the labels of x and y-axis. This was done using xlab and ylab parameters. You can change the name of the labels using the same code, eg. xlab='Speed (mph)', ylab='Stopping distance (ft)'
abline(lm(dist~speed, data=cars), lwd=2) #abline function adds one or more straight lines through the plot that you have active in your environment. lm function is used to fit linear models, where dist is modelled as a function of speed. We also indicate that values for distance and speed can be found in the cars dataset (data = cars). Finally, we specify the thickness of abline function with lwd=2 parameter. 
```

## Data simulation

We can also simulate some data: 

```{r}
set.seed(456) # we can set starting numbers that are used to generate our random values. Random numbers are rarely truly random: https://engineering.mit.edu/engage/ask-an-engineer/can-a-computer-generate-a-truly-random-number/
Babies=data.frame(Age=round(runif(100,1,30)),  Weight=rnorm(100,4000,500)) #We create a new data frame (Babies) where we have Age and Weight as variables. 100 Age values are sampled from random uniform distribution (runif) with lower bound of 1 (minimum) and upper bound of 30 (maximum). 100 Weight values are generated using random normal distribution (rnorm) with mean of 4000 and SD of 500 
Babies$Height=rnorm(100,40+0.2*Babies$Age+0.004*Babies$Weight, 5) # Height is generated using random normal distribution where mean is a function of Age and Weight, while SD is 5. 
Babies$Gender=factor(rbinom(100,1,0.5)) # 100 Gender values are generated using random binomial function with equal probability of being assigned one or the other sex category
levels(Babies$Gender)=c('Girls','Boys') #We levels function to assign Girls and Boys labels to 1 and 0 levels generated by the function
```

We can plot and inspect raw data:

```{r}
par(mfrow=c(1,3), bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16) # par parameter sets global plotting settings. mfrow indicates number of panels for plots (1 row and 3 columns), bty sets type of box around the plot, mar defines margines around the plot, cex magnifies size of labels, while pch sets type of points used in the plot.
plot(Babies$Age, Babies$Height, xlab='Age (months)', ylab='Height (cm)')
plot(Babies$Weight, Babies$Height, xlab='Weight (grams)', ylab='Height (cm)')
boxplot(Babies$Height~Babies$Gender,xlab='Gender', ylab='Height (cm)')
```

We can also check the coding and formatting of the variables in our data frame. 

```{r}
str(Babies)
```

Finally, we can also load the dataset from our local disc drives. The datasets should be placed in your working environment. There are a number of tutorials that guide you how to optimise creation of the new projects, which results in all of your data, code and files being generated and saved at one place. https://r4ds.had.co.nz/workflow-projects.html 

```{r}
inequality<-read.table('inequality.txt', sep='\t', header=T) # read a file in table format and create a data frame from it. sep parameter defines separator in the data - tab delimited format in this case, while it could be also anything else, such as ',' - comma separated values, ' ' - space separated values etc. Header = T defines that the names of the variables are in the first row of the database.

#You can also numerous other extensions, suchs spss sav files, however you will often need additional packages for this. 
#Foreign package - library(foreign) has read.spss function that can be used to read in spss files dataExample<-read.spss('Example.sav', to.data.frame=T)
```

## Linear regression

### One predictor

```{r}
lm1<-lm(Height~Age, data=Babies) # linear model where Height is modelled as a function of Age. 
lm1$coefficients # We can print only the coefficients
```

```{r}
summary(lm1$coefficients) #We can also part of the information that is frequently used to judge significance and importance of predictors  
```

### Two predictors

```{r}
lm2<-lm(Height~Age+Gender, data=Babies) # linear model where Height is analysed as a function of Age and Gender
lm2$coefficients
```

### Main effects and interaction (numerical x categorical)

```{r}
lm3<-lm(Height~Age*Gender, data=Babies) # linear model where Height is modelled as a function of Age and Gender, as well as their interaction
lm3$coefficients
```

### Main effects and interaction (numerical x numerical)

```{r}
lm4<-lm(Height~Age*Weight, data=Babies)
lm4$coefficients
```

### Other information that we get from the linear model

```{r}
lm1<-lm(Height~Age, data=Babies)
summary(lm1)
```

We can calculate R2 step-by-step. First, we need predictions from the model that includes predictor, as this will give us residual sum of squares. 

```{r}
Babies$lm1=predict(lm1, newdata = Babies) # predict Height based on our lm1 model.
Babies$diff=Babies$lm1-Babies$Height #calculate differences between predicted (lm1) and observed values (Height) 
```

We can plot these differences using ggplot. 

```{r}
require(ggplot2)
ggplot()+geom_linerange(data=Babies,aes(x=Age, ymin=Height,ymax=lm1,colour=diff), size=1.2)+geom_line(data=Babies,aes(x=Age, y=lm1), size=1.2)+geom_point(data=Babies, aes(Age, y=Height), size=2)+ylab('Height')+xlab('Age')+ggtitle('SS_residual')
```

A second ingredient for our determination coefficient is sum of squares of total variation in the data. This we can get by building model with intercept only.

```{r}
lm0<-lm(Height~1, data=Babies)
summary(lm0)
Babies$lm0=predict(lm0, newdata = Babies) #predict Height based on average value only
Babies$diff2=Babies$lm0-Babies$Height #calculate difference between predicted (lm0) and observed values (Height)
```

We can plot these differences using ggplot.

```{r}
ggplot()+geom_linerange(data=Babies,aes(x=Age, ymin=Height,ymax=lm0,colour=diff2), size=1.2)+geom_line(data=Babies,aes(x=Age, y=lm0), size=1.2)+geom_point(data=Babies, aes(Age, y=Height), size=2)+ylab('Height')+xlab('Age')+ggtitle('SS_total')
```

The R2 coefficient is:

```{r}
1-(sum(Babies$diff^2)/(sum(Babies$diff2^2)))
```

Improvement in our prediction:

```{r}
Babies$diff3=Babies$lm1-Babies$lm0 #Improvement based on the inclusion of Age as a predictor - differences between the predicted values from (lm1) and intercept only model (lm0)
```

```{r}
ggplot()+geom_linerange(data=Babies,aes(x=Age, ymin=lm1,ymax=lm0,colour=diff3), size=1.2)+geom_line(data=Babies,aes(x=Age, y=lm0), size=1.2)+geom_line(data=Babies, aes(Age, y=lm1), size=1.3, linetype='dotdash')+geom_point(data=Babies, aes(x=Age, y=Height), size=0.9)+ylab('Height')+xlab('Age')+ggtitle('Improvement')+theme(axis.title=element_text(size=14), axis.text =element_text(size=12))
```

F-value:

```{r}
(sum(Babies$diff3^2)/1)/(sum(Babies$diff^2)/98)
```

## Practical aspect of the lecture

```{r}
inequality<-read.table('inequality.txt',sep=',', header=T)#Reading the data in R
head(inequality)
```

Probability density plots: outcomes

```{r}
par(mfrow=c(1,2))
plot(density(inequality$hate_crimes_per_100k_splc, na.rm = T), main='Crimes per 100k') #probability density for hate crimes outcomes. na.rm=T indicates that only cases that are not NAs should be returned
plot(density(inequality$avg_hatecrimes_per_100k_fbi, na.rm = T), main='Average Crimes')
```

Probability density plots: predictors

```{r}
par(mfrow=c(1,2))
plot(density(inequality$median_household_income, na.rm = T), main='Income')
plot(density(inequality$gini_index, na.rm = T), main='Gini')
```

Scatter plots:

```{r}
par(mfrow=c(1,2))
plot(inequality$median_household_income, inequality$avg_hatecrimes_per_100k_fbi, xlab='Median household income',ylab='Avg hatecrimes')
plot(inequality$gini_index, inequality$avg_hatecrimes_per_100k_fbi,xlab='Gini index',ylab='Avg hatecrimes')
```

```{r}
cor(inequality[,c(2,8,12)], use="complete.obs") #calculate correlations where we use only rows that have all values (no NAs). We are only focusing on columns: 2,8 and 12. inequality is a data frame with (n rows, m columns), so we can access only first row by calling inequality[1,], or just first column by inequality[,1], first row and first column would be inequality[1,1]. When using inequality[,c(2,8,12)] am asking for all rows but only second, eight and twelfth column.
```

Stepwise approach in building linear model

```{r}
mod1<-lm(avg_hatecrimes_per_100k_fbi~median_household_income, data=inequality) #modelling avg hatecrimes as a function of median_household_income
summary(mod1)
```

Adding a new predictor and comparing it with the previous model.

```{r}
mod2<-lm(avg_hatecrimes_per_100k_fbi~median_household_income+gini_index, data=inequality)
anova(mod2) #anova type comparison of the model that allows us to see whether newly added predictor explained additional variation in the outcome. We can see changes in the Sum Sq for residuals and for the main effects
```

We can also test whether there is need to adjust influence of median household income across the values of gini index - interaction between our predictors

```{r}
mod3<-lm(avg_hatecrimes_per_100k_fbi~median_household_income*gini_index, data=inequality)
anova(mod1,mod2, mod3) # comparison between three models
```

Summary of the model:

```{r}
summary(mod3)
```

We can visualise the interactions using __interactions__ package.

```{r}
require(interactions)
interact_plot(mod3, pred=median_household_income, modx=gini_index, plot.points = T)
```

Interactive visualisation:

```{r, echo=FALSE}
simulatedD<-data.frame(median_household_income=rep(seq(35500, 76165, by=100), 13), gini_index=rep(seq(0.41,0.53, by=.01), each=407))
simulatedD$Avg_hate_pred<-predict(mod3, newdata=simulatedD) #We need to simulate full matrix of observations - each combination of Gini index and Median Income (increments of 0.1 and 100, respectivelly). Then we predict observations based on our model and use the Simulated data as our predictors. 
```

```{r,fig.width=14, fig.height=5, fig.align='center'}
p<-ggplot(simulatedD, aes(median_household_income, Avg_hate_pred, color=gini_index,frame=gini_index))+geom_point() # Using ggplot to make the plot
plotly::ggplotly(p) #make it interactive using plotly
```

## Model diagnostics

Quantile-quantile plot: Normality

```{r,fig.width=10, fig.height=4,fig.align='center'}
car::qqPlot(mod3)
```

Homoscedasticity: Linearity

```{r,fig.width=10, fig.height=4,fig.align='center'}
car:: residualPlot(mod3, type='rstudent') # we can call car package without loading it into R environment by calling car::
```

Outliers:

```{r}
car:: influenceIndexPlot(mod3) #influence of individual observation on our model
```

Autocorrelation of residuals

```{r}
par(bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
stats::acf(resid(mod3))
```

Predicted versus observed data:

```{r}
par(bty='n',mar = c(5, 4, .1, .1), cex=1.1, pch=16)
plot(predict(mod3),mod3$model$avg_hatecrimes_per_100k_fbi, xlab='Predicted values (model 3)', ylab='Observed values (avg hatecrimes)') #The x-axis is predict(mod3) - predict values based on our model. The y-axis is the data that was used to build the model. I decided to take these values from our model frame (mod3), instead of original data frame (inequalities). 
```

Finally, we can subset our model and exclude data point that might skew our results

```{r}
mod3.cor<-lm(avg_hatecrimes_per_100k_fbi~median_household_income*gini_index, data=inequality, subset=-9) #We subset our data to exclude row 9
summary(mod3.cor)
```
